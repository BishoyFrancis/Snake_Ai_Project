<!doctype html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width initial-scale=1">
<title>SnakeAi.md</title>
<style type="text/css">
.content {
  padding: 100.8px 80px
}
</style>
<style type="text/css">
.content {
  position: relative;
  width: 100%;
  margin: 0 auto;
  max-width: 700px; /* 700px is the width of the post in Medium */
}

/* hide TOC(table of contents). it's height is calculated from the original container */
.content--buffer .table-of-contents {
  height: 0;
}

.content > :first-child,
.content > :first-child > * /* nested blocks */ {
  margin-top: 0;
}

.content > :last-child,
.content > :last-child > * /* nested blocks */ {
  margin-bottom: 0;
}

.mermaid {
  margin-bottom:  1.8em;
}

.page-break {
  page-break-before: always;
}

@media print {
  /* fix | code blocks in PDF export are trimmed */
  .content pre {
    white-space: pre-wrap;
  }
}
</style>
<style type="text/css">



/*
 * Read-only
 *
 * To add a theme:
 *   1. Add a .css file to the same folder.
 *   2. Restart the app. */

:root {
  --line-height: 1.8em;

  background: #fff;
  color: #333;
  font-family: system-ui, sans-serif;
  font-size: 16px;
  font-weight: 400;
  line-height:  1.8em;
}

.content {
  max-width: 626px;
}

/* Quotes
   ---------------- */

blockquote {
  border-left: .2rem solid #ddd;
  color: #999;
  margin-left: 0;
  padding-left: 1rem;
  position: relative;
}

/* Headings
   ---------------- */

h1,
h2,
h3,
h4,
h5,
h6 {
  font-family: system-ui;
  margin-bottom:  1.8em;
  margin-top: calc(1.5 *  1.8em);
}

h1 {
  font-size: 2em;
}

h2 {
  font-size: 1.5em;
}

h3,
h4,
h5,
h6 {
  font-size: 1em;
}

/* Paragraphs */

p {
  margin-bottom:  1.8em;
}

/* Inlines
   ---------------- */

a[href] {
  color: #79b;
  text-decoration: none;
}

a[href] img {
  /* hide link underline */
  box-shadow: 0 10px 0 #fff;
}

kbd {
  border: 2px solid #ddd;
  border-bottom: 3px solid #ddd;
  border-radius: 4px;
  font-family: 'Roboto Mono', monospace;
  font-size: 1rem;
  margin: 0 .2rem;
  padding: .2rem .6rem;
}

strong {
  font-weight: bold;
}

/* Media
   ---------------- */

img {
  max-width: 100%;
}

/* Rules
   ---------------- */

hr {
  border: none;
  border-top: .2rem solid #ddd;
  box-sizing: border-box;
  height: 0;
  padding: 0;
  margin-bottom:  1.8em;
}

/* Tables
   ---------------- */

table {
  border-collapse: collapse;
  border-top: .3rem solid #ddd;
  margin-bottom:  1.8em;
  width: 100%;
}

table td,
table th {
  padding: calc( 1.8em / 4) .6rem;
}

table td:first-child,
table th:first-child {
  padding-left: 0;
}

table td:last-child,
table th:last-child {
  padding-right: 0;
}

table th {
  font-weight: normal;
  text-align: left;
}

table tbody tr:first-child {
  border-top: .2rem solid #ddd;
}

table tbody tr:last-child {
  border-bottom: .3rem solid #ddd;
}

/* Unordered Lists
   ---------------- */

ul {
  list-style: disc;
  padding-left: 2.4rem;
  margin-bottom:  1.8em;
}

/* Ordered Lists
   ---------------- */

ol {
  padding-left: 2.4rem;
  margin-bottom:  1.8em;
}

ol ul,
ol ol,
ul ol,
ul ul {
  margin-bottom: 0;
  padding-left: 2.4rem;
}

ol ol,
ul ol {
  list-style-type: lower-roman;
}

/* Tasks
   ---------------- */

.task-list-item {
  list-style-type: none;
}

.task-list-item input {
  font-size: 1rem;
  margin: 0 0 0 -1.6rem;
  vertical-align: middle;
  width: 1.3rem;
}

.task-list-item p {
  margin-bottom: calc(.5 *  1.8em);
}

/* Math
   ---------------- */

.katex-display {
  padding: 0.6em 0;
  font-size: 1.2em;
  overflow-x: auto;
  border-radius: 4px;
  margin-bottom: 28px;
  text-align: left;
}

.katex--error {
  color: #777;
}

/* Code Blocks
   ---------------- */

code {
  background: #f3f3f3;
  border-radius: 2px;
  color: #444;
  font-family: 'Roboto Mono', monospace;
  font-size: .85em;
  margin: 0 .2em;
  padding: .1em .5em;
}

.content > pre {
  background: #f3f3f3;
  font-family: 'Roboto Mono', monospace;
  margin-bottom:  1.8em;
  padding: calc(.5 *  1.8em) 1.2rem;
  tab-size: 4;
  overflow-x: auto;
}

.content > pre code {
  background: none;
  border: none;
  color: #444;
  margin: 0;
  padding: 0;
}

/* Code
   ---------------- */

.token.comment,
.token.prolog,
.token.doctype,
.token.cdata {
  color: #aaa;
}

.token.operator,
.token.punctuation {
  color: #888;
}

.token.selector,
.token.attr-name,
.token.entity,
.token.url {
  color: #987;
}

.token.tag,
.token.constant,
.token.keyword {
  color: #a7a;
}

.token.function,
.token.attr-value {
  color: #68a;
}

.token.number,
.token.boolean,
.token.regex,
.token.string {
  color: #6a8;
}

.token.variable,
.token.property,
.token.key {
  color: #a66;
}

/* Print
   ---------------- */

@media print {
  :root {
    font-size: 14px !important;
  }
}

</style>
</head>
<body>
<h1 id="snake-ai">Snake Ai</h1>
<p><img title="Snake" alt="Alt" src="https://hackster.imgix.net/uploads/attachments/431013/snake_dvlfwCony2.png?auto=compress%2Cformat&amp;w=900&amp;h=675&amp;fit=min"></p>
<h2 id="what-is-snake-game">What is snake game ?</h2>
<p>Sanke is a popular game from the old days where the player moves the snake inside a rectangular board where the snake grows in length when eating food which randomly spawn . The game concept relies on 2 obstacles the snake itself and the walls . Game ends if hitting the snake body , hitting a board wall , or the snake fills the whole board and there isn't a new place for food then the snake <strong>WINS</strong> ! ðŸŽ‰</p>
<h2 id="project-main-scope">Project Main Scope:</h2>
<p>The project is about the popular snake game known worldwide and the goal is to get the highest possible score and the highest score i could get with this Ai agent was 83 after 2 hours of training loops and after 1000+ Games . so the purpose of the game is the snake to learn to eat food and trying not to die by colliding with the wall or it body . i conquered this problem by using deep Q-Learning approch while this game has alot of different ai solvers approches .
I Started by doing the normal snake game and make sure that all the logic is good and u can test it in a seperate python file as i will mention it below .
then i started thinking about the deep Q-Learning algorithm so i altered the game in play step to add the reward then creating the model with pytorch with 3 layers that will return an action (right , left , straight) that will move the snake upon it we will have a new game state that will enter the neural network and like that untill it dies.</p>
<h2 id="overview">Overview</h2>
<p>Our goal is develop an ai agent to play snake game and acheive the highest score we can get . To solve snake game with artificial intellingence there are various ways mainly divided into 2 categories : <strong>Domain Specific</strong> and <strong>General Purpose</strong> .</p>
<ul>
<li>
<p><strong>Domain Specific :</strong> domain specific solvers aim to maximize the output in a very specific task [<a href="https://en.wikipedia.org/wiki/Weak_AI">Weak AI</a>].</p>
<ul>
<li>Shortest Path Algorithms
<ul>
<li>BFS (Breadth First Search)</li>
<li>DFS (Depth First Search)</li>
<li>A*</li>
</ul>
</li>
<li>Longest Path Algorithms</li>
<li>Hamilton or Hamiltonian Cycle Algorithm</li>
<li>Genetic Evolution</li>
</ul>
</li>
<li>
<p><strong>General Purpose :</strong> general purpose ones donâ€™t aim for solving narrow tasks. Their goal is to be universal and solve a broader spectrum of problems .</p>
<ul>
<li>Reinforcement Learning
<ul>
<li><mark> Deep Q Learning</mark></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>In the following project we will use deep Q learning to solve snake game .</p>
<p><img title="example" alt="Image for post" src="https://miro.medium.com/max/846/1*uQLbjD0rt4LLJgHh_33uSA.gif"></p>
<figcaption>On the left, the AI does not know anything about the game. On the right, the AI is trained and learnt how to play . THIS IS NOT AN EXAMPLE FROM OUR CODE THIS GENERAL EXAMPLE FOR DEEP Q LEARNING ON SNAKE GAME </figcaption> 
<h2 id="how-deep-q-learning-works">How Deep Q Learning Works ?</h2>
<p>In Reinforcement Learning, we have two main components: the <strong><em>environment</em></strong> (our game) and the <strong><em>agent</em></strong> (our Snake). Every time the agent performs an action, the environment gives a <strong>reward</strong> to the agent, which can be positive or negative depending on <em>how good the action was from that specific state</em>. The goal of the agent is to learn what actions maximize the reward.</p>
<p>The game pipeline or the game algorithm works as follows:</p>
<ul>
<li>Q value is randomly initialized</li>
<li>we get the current state of the game</li>
<li>Action is taken from neural network</li>
<li>a new state is acheived after performing the action</li>
<li>update the Q-value with bellman formula</li>
<li>saving game states in memory to re-train the neural network</li>
<li>we repeat last 2 until game ends</li>
</ul>
<hr>
<h2 id="project-components">Project Components:</h2>
<ul>
<li>
<p><strong>State:</strong> A state is an input array to the neural network that represents information of the current state of the game upon it the neural network will perform an action that will lead to a new state .
the state array consists of 11 boolean variables :</p>
<ul>
<li>if there is danger around the snake (left , right , straight) [3]</li>
<li>snake's direction ( up , down , left , right ) [4]</li>
<li>food's position relative to snake's head (above , below , left , right) [4]</li>
</ul>
</li>
<li>
<p><strong>Loss:</strong> The job of a neural network is to minimize the loss, to reduce the difference between the real target and the predicted one. the loss is expressed as:
<img title="Loss Function" alt="loss Function" src="https://miro.medium.com/max/638/1*AZDjvDhZKJnJAclzmtcXuw.png"></p>
</li>
<li>
<p><strong>Reward:</strong> a <strong>positive</strong> reward is only given to the agent when it eats the food target <strong>(+10)</strong>. If the snake hits a wall or hits itself, the reward is <strong>negative (-10)</strong> .</p>
</li>
<li>
<p><strong>Deep Neural Network (PyTorch):</strong> Our Neural Netowrk Consists of 3 layers each layer with 512 (2^9^ ) nodes. The network receives as input the state, and returns as output three values related to the three actions: move left, move right, move straight.</p>
</li>
</ul>
<h2 id="requirements-and-dependcies">Requirements and Dependcies :</h2>
<ul>
<li>Python</li>
<li>Pygame Module</li>
<li>PyTorch</li>
</ul>
<p>To Play the game go to the folder directory open cmd :</p>
<pre><code>python snake_game_human.py
</code></pre>
<p>To Run the agent :</p>
<pre><code>python snake_agent.py	
</code></pre>
<h2 id="game-output-samples">Game Output Samples:</h2>
<h3 id="baby-snake">Baby Snake:</h3>
<p><img alt="BabySnakeFast" src="../../../../Desktop/snake-ai-pytorch-main/gifs/BabySnakeFast.gif"></p>
<h3 id="slightly-learning-snake">Slightly Learning Snake :</h3>
<p><img alt="Alt"></p>
<h3 id="advanced-snake">Advanced Snake:</h3>
<p><img alt="Advanced Snake GIF"></p>

</body>
</html>